{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose the dataset to be imported. The options are mnist & fashion: You chose -> \n",
      "You did not choose a right dataset to import, maybe next time!\n",
      "Please choose the dataset to be imported. The options are mnist & fashion: You chose -> mnist\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "while flag:\n",
    "    mydataset = input(\"Please choose the dataset to be imported. The options are mnist & fashion: You chose -> \")\n",
    "    if mydataset == \"mnist\":\n",
    "        from keras.datasets import mnist\n",
    "        flag = False\n",
    "    elif mydataset == \"fashion\":\n",
    "        from keras.datasets import fashion_mnist\n",
    "        flag = False\n",
    "    else:\n",
    "        print(\"You did not choose a right dataset to import, maybe next time!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are letting the main code to see the other notebooks in the same directory (train, test, model, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'num_classes' (int)\n",
      "Stored 'epochs' (int)\n",
      "Stored 'batch_size' (int)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "%store num_classes\n",
    "%store epochs\n",
    "%store batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'x_train' (ndarray)\n",
      "Stored 'y_train' (ndarray)\n",
      "Stored 'x_test' (ndarray)\n",
      "Stored 'y_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "if mydataset == \"mnist\":\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "elif mydataset == \"fashion\":\n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "%store x_train\n",
    "%store y_train\n",
    "%store x_test\n",
    "%store y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "from test import *\n",
    "from model import *\n",
    "from output import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model by calling the train.ipynb notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 train samples\n",
      "Stored 'test_data' (ndarray)\n",
      "Stored 'test_label' (ndarray)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Stored 'model' (Sequential)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.2453 - acc: 0.9240 - val_loss: 0.1111 - val_acc: 0.9634\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1023 - acc: 0.9686 - val_loss: 0.0847 - val_acc: 0.9749\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0765 - acc: 0.9771 - val_loss: 0.0752 - val_acc: 0.9782\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0615 - acc: 0.9812 - val_loss: 0.0878 - val_acc: 0.9770\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0530 - acc: 0.9845 - val_loss: 0.0878 - val_acc: 0.9789\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0455 - acc: 0.9864 - val_loss: 0.0804 - val_acc: 0.9821\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0394 - acc: 0.9887 - val_loss: 0.0918 - val_acc: 0.9794\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0359 - acc: 0.9895 - val_loss: 0.0840 - val_acc: 0.9804\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0309 - acc: 0.9907 - val_loss: 0.0905 - val_acc: 0.9808\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0304 - acc: 0.9912 - val_loss: 0.0957 - val_acc: 0.9815\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.0293 - acc: 0.9919 - val_loss: 0.0861 - val_acc: 0.9827\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.0267 - acc: 0.9925 - val_loss: 0.0915 - val_acc: 0.9830\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0258 - acc: 0.9927 - val_loss: 0.0941 - val_acc: 0.9830\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0236 - acc: 0.9936 - val_loss: 0.1057 - val_acc: 0.9824\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0234 - acc: 0.9933 - val_loss: 0.0992 - val_acc: 0.9836\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0210 - acc: 0.9948 - val_loss: 0.0966 - val_acc: 0.9836\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0206 - acc: 0.9947 - val_loss: 0.1143 - val_acc: 0.9817\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.0183 - acc: 0.9949 - val_loss: 0.1156 - val_acc: 0.9829\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0199 - acc: 0.9950 - val_loss: 0.1310 - val_acc: 0.9811\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0181 - acc: 0.9954 - val_loss: 0.1159 - val_acc: 0.9832\n"
     ]
    }
   ],
   "source": [
    "%run ./train.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model by calling the test.ipynb notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.11593726694437842\n",
      "Test accuracy: 0.9832\n"
     ]
    }
   ],
   "source": [
    "%run ./test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
